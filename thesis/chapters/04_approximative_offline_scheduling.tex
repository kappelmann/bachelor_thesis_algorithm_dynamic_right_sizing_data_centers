% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Approximative Offline Scheduling}\label{chap:approx_offline_scheduling}
Heretofore, we have derived two optimal offline algorithms for our scheduling problem. Unfortunately, the algorithm's runtime complexities are exponential in the input size of the number of servers $m$. Needless to say, we want to reduce this exponential runtime. For this, we must slightly loosen our aspirations, that is we move to approximative methods. Further, as we will see in the next section, we need to assume that our convex operating costs function $f$ is non-negative and monotonically increasing; however, this restriction is of no great significance since in practice most operating costs functions fulfill this requirement.\unsure{Any reference?} 

In this chapter, we will first modify our algorithm derived in Section~\ref{sec:opt_offline_pseudo_lin} to obtain a 2-optimal offline algorithm with linear runtime complexity. As a next step, we will generalize our first approach to allow for arbitrary $1+\beps$-approximations with TODO complexity.

\section{A 2-Optimal Algorithm}
Recall our algorithm and its corresponding graph $G$ derived in Section~\ref{sec:opt_offline_pseudo_lin}. The algorithm's runtime complexity of $\Theta(Tm)$ is determined by the number of nodes and edges of $G$. Since we desire to reduce our runtime complexity, we need to reduce the number of nodes and edges in $G$. In particular, we must get rid of the factor $m$. This factor is a consequence of the ``height'' of our graph, that is the number of nodes in each layer. Therefore, we have to ``thin out'' $G$ by reducing its number of nodes in each layer.

As we saw in Equation~\eqref{eq:inp_size}, the size of our input $\inp$ is given by $\mathcal{O}\bigl(T\log_2(m)+\log_2(\beta)\bigr)$. Consequently, in order to obtain a linear runtime complexity, we want to reduce the graph's height from $m+1$ to a logarithmic height of $\mathcal{O}\bigl(\log(m)\bigr)$. Given this observation, it seems natural for a computer scientist to choose a logarithmic scale for the number of servers in each layer; that is, instead of adding a node for each possible number of active servers (i.e.\ $0,1,\dotsc,m$), we only add nodes for logarithmic choices (i.e.\ $0,2^0,2^1,\dotsc,2^{\lfloor\log_2(m)\rfloor},m$). More formally, given a problem instance $\inp$, we set
\begin{align*}
	b&\coloneqq\lfloor\log_2(m)\rfloor\\
	B&\coloneqq\{0,2^0,2^1,\dotsc,2^b,m\}
\end{align*}
where $B$ will subsequently represent the set of possible scheduling choices at each time slot. Using this set of possible choices, we can then consider the following adaption of our former graph:
\begin{align*}
	V&\coloneqq\bigl\{v_{x,t\downarrow}\mid x\in B,t\in[T]\bigr\}\dotcup\bigl\{v_{x,t\uparrow}\mid x\in B, t\in[T-1]\bigr\}\dotcup\{v_{0,0}\}\\
	E_s&\coloneqq\bigl\{(v_{0,0},v_{x,1\downarrow})\mid x\in B\bigr\}\\
	E_\downarrow&\coloneqq\bigl\{(v_{2^i,t\downarrow},v_{2^{i-1},t\downarrow})\mid i\in[b],t\in[T]\bigr\}\dotcup\bigl\{(v_{2^0,t\downarrow},v_{0,t\downarrow})\mid t\in[T]\bigr\}\dotcup\\
	&\phantom{{}\coloneqq{}}\bigl\{(v_{m,t\downarrow},v_{2^b,t\downarrow})\mid t\in[T]\bigr\}\\
	E_\uparrow&\coloneqq\bigl\{(v_{2^{i-1},t\uparrow},v_{2^i,t\uparrow})\mid i\in[b],t\in[T-1]\bigr\}\dotcup\bigl\{(v_{0,t\uparrow},v_{2^0,t\uparrow})\mid t\in[T-1]\bigr\}\dotcup\\
	&\phantom{{}\coloneqq{}}\bigl\{(v_{2^b,t\uparrow},v_{m,t\uparrow})\mid t\in[T-1]\bigr\}\\
	E_{\downarrow\uparrow}&\coloneqq\bigl\{(v_{x,t\downarrow},v_{x,t\uparrow})\mid x\in B,t\in[T-1]\bigr\}\\
	E_{\uparrow\downarrow}&\coloneqq\bigl\{(v_{x,t\uparrow},v_{x,t+1\downarrow})\mid x\in B,t\in[T-1]\bigr\}\\
	E&\coloneqq E_s\dotcup E_\downarrow\dotcup E_\uparrow\dotcup E_{\downarrow\uparrow}\dotcup E_{\uparrow\downarrow}\\
	c_G(e)&\coloneqq
	\begin{cases}
		\costs(0,x,\lambda_1), & \text{if $e=(v_{0,0},v_{x,1\downarrow})\in E_s$}\\
		\opcosts(x,\lambda_{t+1}), & \text{if $e=(v_{x,t\uparrow},v_{x,t+1\downarrow})\in E_{\uparrow\downarrow}$}\\
		(x'-x)\beta, & \text{if $e=(v_{x,t\uparrow},v_{x',t\uparrow})\in E_\uparrow$}\\
		0, & \text{if $e\in(E_\downarrow\dotcup E_{\downarrow\uparrow})$}
	\end{cases}\\
	G&\coloneqq(V,E,c_G)
\end{align*}
A more appealing, graphical representation can be found in the following figure.
\begin{figure}[H]
\includestandalone[width=\textwidth]{../figures/graph_lin_approx_2}
\caption{Graph for a linear, 2-optimal offline algorithm; the path of the topological sorting is highlighted in red. Note that $(2^i-2^{i-1})\beta =2^{i-1}\beta$.}
\label{fig:graph_lin_approx_2}
\end{figure}
The nodes' and edges' semantical meaning and the graph's working principle stays similar to that given in Section~\ref{sec:opt_offline_pseudo_lin}. Again, by following the colored path of the topological sorting, we can work our way through the graph to calculate the shortest paths, ultimately reaching the destination $v_{0,T\downarrow}$. Since some possible scheduling choices, however, are not representable in this new graph, we may just obtain approximative costs for our nodes. Thus, the shortest path in our graph might not correspond to an optimal schedule, but it will at least correspond to an approximative one. Before we start to establish the graph's approximation guarantee, we first have to conduct some observations. We start by making a convenient definition that helps us to identify schedules that are representable in our graph.
\begin{defn}[Restricted schedules]
Given an input $\inp$ and a set $A\subseteq\fromto{0}{m}$, we say that a schedule $\mx=(x_1,\dotsc,x_T)$ is \emph{$A$-restricted} if $\mx$ only uses scheduling coices contained in $A$, that is $\mx$ satisfies $\forall t\in[T](x_t\in A)$.
\end{defn}
Evidently, our graph is able to represent every $B$-restricted schedule. We shall now take a look on the incurring operating costs of such an $B$-restricted schedule $\mx'$. Since we are forced to schedule a number of servers contained in $B$, we might not be able to choose an optimal scheduling choice that minimizes the schedule's operating costs. Instead, we may choose the nearest scheduling choice which is contained in $B$. For instance, if the optimal scheduling strategy at some timeslot $t$ would be to choose $x_t=3$ servers (which is not a power of two), we may instead have to choose $x_t'=4\in B$ servers for our $B$-restricted schedule. One might suspect that this strategy would incur at most twice as much operating costs as an optimal schedule. This, however, is sadly not the case, as one can see in the following example.
\begin{exmpl}
Let $\inp=\bigl(m=4,T=5,\Lambda=(3,3,3,3,3),\beta=0,f\bigr)$ be the input for a problem instance where $f(\lambda)=(\lambda-1)^2$. Since we need at least 3 active servers at any timeslot, any $B$-restricted schedule $\mx'=(x_1',\dotsc,x_5')$ forces us to constantly use $x_t'=4$ active machines. An optimal schedule $\mx=(x_1,\dotsc,x_5)$, on the other hand, is able to minimize its costs by constantly scheduling $x_t=3$ servers. Let us compare the costs between $\mx'$ and $\mx$. The schedules' costs are given by
\begin{align*}
	\costs(\mx)&\stackrel{\eqref{eq:mx_schedule_total_costs}}{=}\sum\limits_{t=1}^{5}\bigl(\overbrace{x_tf(\lambda_t/x_t)}^{3(3/3-1)^2}+\overbrace{\swcosts(x_{t-1},x_t)}^{0\max\{\,\cdots\}}\bigr)=5\cdot3\Bigl(\frac{3}{3}-1\Bigr)^2=0\\
	\costs(\mx')&\stackrel{\eqref{eq:mx_schedule_total_costs}}{=}\sum\limits_{t=1}^{5}\bigl(\overbrace{x_t'f(\lambda_t/x_t')}^{4(3/4-1)^2}+\overbrace{\swcosts(x_{t-1}',x_t')}^{0\max\{\,\cdots\}}\bigr)=5\cdot4\Bigl(\frac{3}{4}-1\Bigr)^2=\frac{20}{16} 
\end{align*}
Albeit our approximative schedule uses only one server in addition, the schedule's cost is already inestimably higher than that of an optimal schedule $\mx$, preventing any sensible approximation estimation. Naturally, we may ask ourselves how this explosion of costs is even possible. Evidently, the switching costs are not the root of this explosion since $\beta=0$. Thus, we shall take a closer look on the used operating costs function. The optimal schedule $\mx$ evenly distributes every load $\lambda_t=3$ to $x_t=3$ servers. Hence, every active server has to process a load of $\frac{\lambda_t}{x_t}=1$ at every time step, incurring costs of $f(1)=0$. On the other hand, the approximative schedule $\mx'$ is able to distribute every load to 4 active machines. Thus, every machine incurs costs of $f(\frac{3}{4})=\frac{1}{16}$. This observation seems rather surprsing: Although every server has to process a smaller load using $\mx'$, the incurred operating costs of each server turn out to be higher. Intuitevly, however, we would expect that a less stressed machine would incur less costs. This surprising behavior is due to the fact that our operating costs function $f$ is not monotonically increasing, as one can see in the following figure.
\begin{figure}[H]
\centering
\includestandalone{../figures/non_mono_incr_f}
\caption{Example of a non-monotonically increasing operating costs function \makebox{$f(\lambda)=(\lambda-1)^2$}, where smaller loads incur higher costs.}
\label{fig:non_mono_incr_f}
\end{figure}
\end{exmpl}
The above example shows us that our graph may not able to deliver a sensible approximation when dealing with general convex operating costs functions $f$. Luckily, this inconvenience can solved by additionally assuming that $f$ is non-negative and monotonically increasing\unsure{note that in practice used functions are mostly monotone+non-neg.?}. To see this, assume that at some timeslot $t$ the scheduling choice $x_t$ minimizes the operating costs to process the load $\lambda_t$. Then let $x_t'\in B$ the next scheduling choice representable in $G$. Since $x_t$ minimizes the operating costs at timeslot $t$, we have
\begin{equation*}
	\opcosts(x_t,\lambda_t)\le\opcosts(x_t',\lambda_t)\stackrel{\eqref{eq:mx_schedule_op_costs}}{=}x_t'f\Bigl(\frac{\lambda_t}{x_t'}\Bigr)
\end{equation*}
Further, since $B$ contains all powers of two up to $m$, we have $x_t\le x_t'\le 2x_t$. If we additionally assume that $f$ is non-negative, we can infer that
\begin{equation*}
	x_t'f\Bigl(\frac{\lambda_t}{x_t'}\Bigr)\le2x_tf\Bigl(\frac{\lambda_t}{x_t'}\Bigr)
\end{equation*}
Now, using the fact that $x_t\le x_t'$ and assuming that $f$ is monotonically increasing, we have
\begin{equation*}
	2x_tf\Bigl(\frac{\lambda_t}{x_t'}\Bigr)\le 2x_tf\Bigl(\frac{\lambda_t}{x_t}\Bigr)\stackrel{\eqref{eq:mx_schedule_op_costs}}{=}2\opcosts(x_t,\lambda_t)
\end{equation*}
Ultimately, we can combine our observations and conclude
\begin{equation*}
	\opcosts(x_t,\lambda_t)\le\opcosts(x_t',\lambda_t)\le2\opcosts(x_t,\lambda_t)
\end{equation*}
which shows us that our approximative scheduling choice incurs at most twice as much operating costs as an optimal scheduling strategy. We thus subsequently restrict ourselves to non-negative, monotonically increasing convex cost functions.

Next, we shall take a look on the incurring switching costs of a $B$-restricted schedule $\mx'$. Again, given an optimal scheduling choice $x_t$, we use the idea to choose the nearest scheduling choice $x_t'$ that is contained in $B$ to construct $\mx'$. Once more, one might hope that $\mx'$ would incur at most twice as much switching costs as an optimal schedule. Needless to say, the next example dashes this hope.
\begin{exmpl}
Let $\inp=\bigl(m=8,T=5,\Lambda=(9,7,9,7,9),\beta=1,f\bigr)$ be the input for a problem instance where $f(\lambda)=0$. Our possible scheduling choices are then given by $B=\{0,1,2,4,8\}$, and one optimal schedule is given by $\mx=(9,7,9,7,9)$. The $B$-restricted schedule corresponding to $\mx$ is then given by $\mx'=(16,8,16,8,16)$. The schedules' costs amount to
\begin{align*}
	\costs(\mx)&\stackrel{\eqref{eq:mx_schedule_total_costs}}{=}\sum\limits_{t=1}^{5}\bigl(\overbrace{x_tf(\lambda_t/x_t)}^{x_t\cdot 0}+\overbrace{\swcosts(x_{t-1},x_t)}^{\max\{0,x_t-x_{t-1}\}}\bigr)=9+0+2+0+2=13\\
	\costs(\mx')&\stackrel{\eqref{eq:mx_schedule_total_costs}}{=}\sum\limits_{t=1}^{5}\bigl(\overbrace{x_t'f(\lambda_t/x_t')}^{x_t'\cdot 0}+\overbrace{\swcosts(x_{t-1}',x_t')}^{\max\{0,x_t'-x_{t-1}'\}}\bigr)=16+0+8+0+8=32
\end{align*}
The approximative schedule's cost is thus not 2-competetive compared to the optimal schedule. Of course, we are again curious about how this cost explosion is possible. Since we set $f(\lambda)=0$, that is our servers do not incur operating costs, this explosion is evidently due to the increased switching costs of $\mx'$. The problem in this case is the oscillating behavior of $\mx$ around a power of two (namely $8=2^3$), as one can see in the following figure. 
\begin{figure}[H]
\captionsetup[subfigure]{labelformat=empty}
\begin{subfigure}[b]{0.47\textwidth}
\includestandalone[width=\textwidth]{./../figures/switching_costs_not_2_opt_1}
	\caption{\underline{Optimal schedule $\mx$:} Note how the schedule oscillates around 8 (a power of two).}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.47\textwidth}
\includestandalone[width=\textwidth]{../figures/switching_costs_not_2_opt_2}
	\caption{\underline{Approximative schedule $\mx'$:} The approximative schedule is restricted to powers of two.}
\end{subfigure}
\caption{Comparison between an optimal and an approximative schedule. The approximative schedule incurs more than twice as much switching costs.}
\label{fig:adaption-schedule}
\end{figure}
\end{exmpl}
So, is this the end of our hunt for a 2-optimal approximation? No, certainly not! Although our naive approach was to no avail, there is indeed a better $B$-restricted schedule for our example. Instead of following the optimal schedule's oscillation, we can simply use a schedule that stays put during these oscillating steps, that is we can use the schedule $\mx'=(16,16,16,16,16)$ with costs $\costs(\mx')=16$. Obviously, this seems like a rather trivial example since we set $f(\lambda)=0$, and hence we do not need to worry about the new schedule's operating costs. However, it indeed turns out that making the right choice between following the optimal schedule's oscillation and staying put will always allow us to acquire a 2-optimal approximation. This observation is the key part of the next lemma. Before we dive into the lemma and its proof, we make a handy definition:
\begin{defn}
Let $\mx=(x_1,\dotsc,x_T)$ be a schedule and $t\in[T]$ with $x_{t-1}\neq 0$. We say that $\mx$ changes its \emph{2-state} at time $t$ if $x_t$ lies between a different pair of powers of two than its predecessor, that is $x_t$ satisfies
\begin{equation*}
	x_t\notin\bigl[2^{\lfloor \log_2(x_{t-1})\rfloor},2^{\lceil \log_2(x_{t-1}+1)\rceil}\bigr]
\end{equation*}
\end{defn}
Now we are geared up to deal with the main work of this section.
\begin{lem}\label{lem:transform_schedule_approx_2}
Let $\mx$ be a schedule for $\inp$. There exists a $B$-restricted schedule $\mx'$ satisfying \makebox{$\costs(\mx')\le2\costs(\mx)$}.
\end{lem}
\begin{proof}
Let $\mx=(x_1,\dotsc,x_T)$ be a schedule for $\inp$. We need to construct a $B$-restricted schedule $\mx'=(x_1',\dotsc,x_T')$ such that \makebox{$\costs(\mx')\le2\costs(\mx)$}.
First, we note that if $\mx$ powers down all its servers at some timeslot $t\in[T-1]$, i.e.\ $x_t=0$, we can split $\mx$ into two subschedules \makebox{$\mx_1=(x_1,\dotsc,x_{t-1})$} and \makebox{$\mx_2=(x_{t+1},\dotsc,x_T)$}. By setting $x_t'\coloneqq0$, it suffices to prove the claim for $\mx_1$ and $\mx_2$, as we can then construct the 2-competitive schedule by setting $\mx'\coloneqq(\mx_1',x_t',\mx_2')$. Thus, by recursively applying this method, we can reduce our proof to a list of subschedules $\mx_1,\dotsc,\mx_N$ that never power down all servers. Consequently, without loss of generality, we can subsequently assume that $\mx$ never powers down all its servers, that is $x_t>0$ for all $t\in[T]$. 
	
For the initial start-up process, we can simply move to the next power of 2 larger than $x_1$, that is we set $x_1'=2^{\lceil\log_2(x_1+1)\rceil}$. Since $x_1\in[m]$, we know that $x_1'\le2x_1$ and thus $\beta x_1'\le2\beta x_1$; in other words, the start-up switching costs of $\mx'$ are 2-competitive. Next, we show that every period between two 2-state changes of $\mx$ can be transformed to a 2-competitive period in $\mx'$. For this, let $i,j\in[T]$ with $i<j$ be the first timeslots at which $\mx$ changes its 2-state. Let us have a look on the possible behaviors of $\mx$:
\begin{figure}[H]
\captionsetup[subfigure]{labelformat=empty}
\begin{subfigure}[b]{0.47\textwidth}
\includestandalone[width=\textwidth]{../figures/schedule_behavior_up}	
\caption{\underline{Rising schedule:} Stays between $2^j$ and $2^{j+1}$ and then rises above $2^{j+1}$.}
\end{subfigure}
\hfill
\begin{subfigure}[b]{0.47\textwidth}
\includestandalone[width=\textwidth]{../figures/schedule_behavior_up}	
\caption{\underline{Rising schedule:} Stays between $2^j$ and $2^{j+1}$ and then rises above $2^{j+1}$.}
\end{subfigure}
\caption{Possible schedule behaviors}
\end{figure}

Let $l\coloneqq\min\{2^{k+1},m\}$. TODO $2d<l-2^k$

If $\opcosts(\mx_{i,j}^{2^k})+\beta(l-2^k)$ is 2-competitive, we are done; hence, assume that this is not the case. We then need to show that $\opcosts(\mx_{i,j}^l)$ is 2-competitive. First, by assumption, we know that $\opcosts(\mx_{i,j}^k)+\beta 2^k$ is not 2-competitive, that is we have
\begin{equation*}
	2\bigl(\opcosts(\mx_{i,j})+\beta d\bigr)<\opcosts(\mx_{i,j}^k)+\beta 2^k
\end{equation*}
We know that $\mx_{i,j}^k$ uses at most twice as many active servers as $\mx_{i,j}$, and thus $\mx_{i,j}^k$ incurs at most twice as much operating costs as $\mx_{i,j}$. Consequently, the switching costs of $\mx_{i,j}^k$ must significantly outweight those of $\mx_{i,j}$. Hence, it seems interesting to get an estimation for $\beta$. Rearranging the previous inequality gives us
\begin{equation*}
	\frac{2\opcosts(\mx_{i,j})-\opcosts(\mx_{i,j}^k)}{2^k-2d}<\beta
\end{equation*}
This allows us to find a lower bound for the costs using $\mx_{i,j}$:
\begin{align*}
	\opcosts(\mx_{i,j})+\beta d&>\opcosts(\mx_{i,j})+\frac{2\opcosts(\mx_{i,j})-\opcosts(\mx_{i,j}^k)}{2^k-2d}d\\
	&=\frac{\opcosts(\mx_{i,j})(2^k-2d)+2d\opcosts(\mx_{i,j})-d\opcosts(\mx_{i,j}^k)}{2^k-2d}\\
	&=\frac{2^k\opcosts(\mx_{i,j})-d\opcosts(\mx_{i,j}^k)}{2^k-2d}
\end{align*}
Next, since we want to prove that $\opcosts(\mx_{i,j}^{k+1})$ is 2-competitive, we have to show that the following cost difference is non-negative:
\begin{align*}
	2\bigl(\opcosts(\mx_{i,j})+\beta d\bigr)-\opcosts(\mx_{i,j}^{k+1})
\end{align*}
We can use our just derived lower bound for $\opcosts(\mx_{i,j})+\beta d$ to estimate the difference:
\begin{align*}
	2\bigl(\opcosts(\mx_{i,j})+\beta d\bigr)-\opcosts(\mx_{i,j}^{k+1})&>2\Bigl(\frac{2^k\opcosts(\mx_{i,j})-d\opcosts(\mx_{i,j}^k)}{2^k-2d}\Bigr)-\opcosts(\mx_{i,j}^{k+1})\\
	&=\frac{2^k\opcosts(\mx_{i,j})-d\opcosts(\mx_{i,j}^k)-(2^{k-1}-d)\opcosts(\mx_{i,j}^{k+1})}{2^{k-1}-d}
\end{align*}
Thus, it suffices to show that
\begin{align*}
	&&\frac{2^k\opcosts(\mx_{i,j})-d\opcosts(\mx_{i,j}^k)-(2^{k-1}-d)\opcosts(\mx_{i,j}^{k+1})}{2^{k-1}-d}&\ge 0\\
	&\stackrel{2^{k-1}>d}{\iff}&2^k\opcosts(\mx_{i,j})-d\opcosts(\mx_{i,j}^k)-(2^{k-1}-d)\opcosts(\mx_{i,j}^{k+1})&\ge 0
\end{align*}
For this, we have to take a closer look on the the schedules' operating costs:
\begin{align*}
	&&&2^k\opcosts(\mx_{i,j})-d\opcosts(\mx_{i,j}^k)-(2^{k-1}-d)\opcosts(\mx_{i,j}^{k+1})\\
	&\stackrel{\eqref{eq:mx_schedule_op_costs}}{=}&&2^k\sum\limits_{t=i}^j\Bigl(x_tf\Bigl(\frac{\lambda_t}{x_t}\Bigr)\Bigr)-d\sum\limits_{t=i}^j\Bigl(2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-(2^{k-1}-d)\sum\limits_{t=i}^j\Bigl(2^{k+1}f\Bigl(\frac{\lambda_t}{2^{k+1}}\Bigr)\Bigr)
\end{align*}
First, we note that $x_t<2^k$ and $2^k<2^{k+1}$. Together with the fact that $f$ is monotonically increasing, we infer that
\begin{align*}
	&&&2^k\sum\limits_{t=i}^j\Bigl(x_tf\Bigl(\frac{\lambda_t}{x_t}\Bigr)\Bigr)-d\sum\limits_{t=i}^j\Bigl(2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-(2^{k-1}-d)\sum\limits_{t=i}^j\Bigl(2^{k+1}f\Bigl(\frac{\lambda_t}{2^{k+1}}\Bigr)\Bigr)\\
	&\ge&&2^k\sum\limits_{t=i}^j\Bigl(x_tf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-d\sum\limits_{t=i}^j\Bigl(2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-(2^{k-1}-d)\sum\limits_{t=i}^j\Bigl(2^{k+1}f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)
\end{align*}
Next, TODO f pos.\ and no oscillating
\begin{align*}
	&&&2^k\sum\limits_{t=i}^j\Bigl(x_tf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-d\sum\limits_{t=i}^j\Bigl(2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-(2^{k-1}-d)\sum\limits_{t=i}^j\Bigl(2^{k+1}f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)\\
	&\ge&&2^k\sum\limits_{t=i}^j\Bigl((2^k-d)f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-d\sum\limits_{t=i}^j\Bigl(2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-(2^{k-1}-d)\sum\limits_{t=i}^j\Bigl(2^{k+1}f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)
\end{align*}
Hence, to finish the case, it suffices to show that
\begin{align*}
	2^k\sum\limits_{t=i}^j\Bigl((2^k-d)f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-d\sum\limits_{t=i}^j\Bigl(2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-(2^{k-1}-d)\sum\limits_{t=i}^j\Bigl(2^{k+1}f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)\ge 0
\end{align*}
which is no difficulty:
\begin{align*}
	&&&2^k\sum\limits_{t=i}^j\Bigl((2^k-d)f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-d\sum\limits_{t=i}^j\Bigl(2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-(2^{k-1}-d)\sum\limits_{t=i}^j\Bigl(2^{k+1}f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)\\
	&=&&\sum\limits_{t=i}^j\Bigl((2^{2k}-d2^k)f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-\sum\limits_{t=i}^j\Bigl(d2^kf\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)-\sum\limits_{t=i}^j\Bigl((2^{2k}-d2^{k+1})f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)\\
	&=&&\sum\limits_{t=i}^j\Bigl((2^{2k}-d2^k-d2^k-2^{2k}+d2^{k+1})f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)\\
	&=&&\sum\limits_{t=i}^j\Bigl((\underbrace{-2d2^k}_{-d2^{k+1}}+d2^{k+1})f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)=\sum\limits_{t=i}^j\Bigl(0\cdot f\Bigl(\frac{\lambda_t}{2^k}\Bigr)\Bigr)=0
\end{align*}	
By gradually applying the above procedure to $\mx$, beginning with $i=1$ and stopping with $j=T$, we obtain a $B$-restricted schedule $\mx'$ that satisfies $\costs(\mx')\le2\costs(\mx)$.
\end{proof}
Safe in the knowledge that there always exists a 2-optimal, $B$-restricted schedule, we are just left with the verification of our new graph. We want to establish a bijection between $B$-restricted schedules and reasonable paths. Since we did not change the general construction idea of our graph, this verification turns out to be very similar to that done in Section~\ref{sec:opt_offline_pseudo_lin}. For the proof of the next lemma, we need to recall our notion of ``maximum'' nodes $x_t$ in reasonable paths $P$, as described in Definition~\ref{defn:max_path_node}, as well as that $B=\{0,2^0,2^1,\dotsc,2^b,m\}$.
\begin{lem}\label{lem:sched_reasn_path_approx_2}
Let $\bm{\mx}$ be the set of all $B$-restricted schedules for $\inp$, and let $\bm{\mathcal{P}}$ be the set of all reasonable paths. The map
\begin{equation*}
	\Phi:\bm{\mathcal{P}}\rightarrow\bm{\mx},\quad P\mapsto (x_1,\dotsc,x_T)
\end{equation*}
is a bijection satisfying $\costs(P)=\costs\bigl(\Phi(P)\bigr)$.
\end{lem}
\begin{proof}
The proof is analogous to the proof of Lemma~\ref{lem:sched_reasn_path_pseudo_lin} considering that we conduct logarithmic instead of incremental switching steps.\unsure{Is this okay?}
\end{proof}
Finally, we arrive at the main result of this section.
\begin{thm}\label{thm:approx_2}
Any shortest, reasonable path $P$ corresponds to a 2-optimal, $B$-restricted schedule $\mx$ for $\inp$ with $\costs(P)=\costs(\mx)$.
\end{thm} 
\begin{proof}
By Lemma~\ref{lem:sched_reasn_path_approx_2}, we have a bijection $\Phi$ between reasonable paths $P$ and $B$-restricted schedules obeying $\costs(P)=\costs\bigl(\Phi(P)\bigr)$. Thus, we have 
\begin{equation*}
	\costs(P)\text{ minimal}\iff \costs\bigl(\Phi(P)\big)\text{ minimal}
\end{equation*}
Now let $P$ be a shortest, reasonable path, and let $\mx^*$ be an optimal schedule for $\inp$. We have to verify that $\costs\bigl(\Phi(P)\bigr)\le 2\costs(\mx^*)$. By Lemma~\ref{lem:transform_schedule_approx_2}, we know that there exists a $B$-restricted schedule $\mx'$ such that $\costs(\mx')\le 2\costs(\mx^*)$. Since $\Phi$ is a bijection, and $P$ is a shortest, reasonable path, we know that $\costs\bigl(\Phi(P)\bigr)\le\costs(\mx')$. Thus, we conclude that 
\begin{equation*}
	\costs(P)=\costs\bigl(\Phi(P)\bigr)\le\costs(\mx')\le 2\costs(\mx^*)
\end{equation*}
and the claim follows.
\end{proof}
Again, it is not difficult to show that also shortest paths which are not reasonable can be transformed to a desired 2-optimal schedule.
\begin{cor}\label{cor:opt_sched_short_path_pseudo_lin}
Any shortest path $P$ from $v_{0,0}$ to $v_{0,T\downarrow}$ can be transformed to a 2-optimal, $B$-restricted schedule $\mx$ for $\inp$ with $\costs(\mx)=\costs(P)$.
\end{cor}
\begin{proof}
Let $P$ be a shortest path from $v_{0,0}$ to $v_{0,T\downarrow}$. By using a small adaption of Proposition~\ref{prop:path_to_reasn_path} that uses logarithmic instead of incremental switching steps\unsure{Is this okay?}, we can transform $P$ to a reasonable path $P'$ with $\costs(P')=\costs(P)$.
In turn, $P'$ corresponds to a 2-optimal, \makebox{$B$-restricted} schedule $\mx$ with $\costs(\mx)=\costs(P')=\costs(P)$ by Theorem~\ref{thm:approx_2}, which finishes the proof.
\end{proof}


\section{A $1+\beps$-Optimal Algorithm}
