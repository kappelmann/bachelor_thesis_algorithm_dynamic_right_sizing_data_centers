\documentclass[hidelinks]{article}
\usepackage[english]{babel} 
\usepackage[utf8x]{inputenc}
%% Hyperlinks 
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    linktoc=all,
    urlcolor={blue!80!black}
}
%% Graphics
\usepackage{graphicx}
\usepackage{float}

\usepackage{enumerate}
% Math packages
\usepackage{amsmath}
\usepackage{amssymb}
% Algorithms
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\newcommand\Let[2]{\State #1 $\gets$ #2}
\algrenewcomment[1]{\(\qquad \triangleright\) #1}
\newcommand\Blet[2]{\State \textbf{let} #1 \textbf{be} #2}
\usepackage{mathtools}
% Proof system
\usepackage{amsthm}
\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{bsp}[thm]{Example}
\newtheoremstyle{rem} % name
    {\topsep}                    % Space above
    {\topsep}                    % Space below
    {}                   % Body font
    {}                           % Indent amount
    {\bf}                   % Theorem head font
    {:}                          % Punctuation after theorem head
    {.5em}                       % Space after theorem head
    {}  % Theorem head spec (can be left empty, meaning ‘normal’)
\theoremstyle{rem}
\newtheorem*{remark}{Note}
%\usepackage{xpatch}
%\makeatletter
%% Remove last point from definitions, theorems, etc.
%\xpatchcmd{\@thm}{\thm@headpunct{.}}{\thm@headpunct{\\}}{}{}
%\makeatother

% Seitenränder
%TODO originally 1.5 in
\usepackage[margin=1.3in]{geometry}
% citations
\usepackage{cite}
% tables and colors
\usepackage[table]{xcolor}
% Graphs
\usepackage{tikz}
\usetikzlibrary{calc,arrows.meta,positioning}
\usepackage{tikz-3dplot}
\usepackage{pgfplots}
\setlength{\parindent}{0pt}

% Title of document
\title{Power management - Dynamic Programming}
% Author
\author{Kevin Kappelmann\\
  \multicolumn{1}{p{.7\textwidth}}{\centering\emph{Chair for Theoretical Computer Science,\\
  Technical University of Munich}}}  

% Custom commands
\newcommand{\mx}{\mathcal{X}}

\pagestyle{plain}

%------------------------------------------------------------------------------
\begin{document}

\pagenumbering{arabic}

\begin{sloppypar}
\section{Introduction}
\subsection{Input and conventions}
TODO: rewrite in nice paragraph\\
Input:
\begin{itemize}
	\item $m\in\mathbb{N}$: Number of homogeneous servers
	\item $T\in\mathbb{N}$: Number of time steps
	\item $\beta\in\mathbb{R}_{\ge 0}$: Power up costs
	\item $\lambda_0,\ldots,\lambda_{T}\in[0,m]$: Arrival rates
\end{itemize}
Notations:
\begin{itemize}
	\item Let $\lambda_{i,t}$ be the assigned arrival rate at time t for server i
	\item Let $x_t$ be the number of active servers at time t
	\item Let $\mx\coloneqq(x_0,\ldots,x_T)$ be the sequence of active servers
	\item If $A=(a_0,\ldots,a_n)$ is a tuple with $n+1$ entries, we write $A(i)$ for the i-th component of A with $0\le i\le n$
\end{itemize}
Requirements:
\begin{itemize}
	\item Convex cost function $f$
	\item Power down costs are w.l.o.g.\ equal to 0
	\item $\forall t\in \{0,\ldots,T\}:\sum\limits_{i=1}^{m}{\lambda_{i,t}=\lambda_t}$
	\item $\lambda_0=\lambda_T=0$
	\item $\mx(0)=\mx(T)=0$, i.e.\ all servers are powered down at $t=0$ and $t=T$
\end{itemize}

\subsection{Preliminaries}
\begin{lem}\label{lem:share}
	Given a convex cost function $f$, $x$ active servers and an arrival rate $\lambda$, the best method is to assign each server a load of $\lambda/x$.
\end{lem}
\begin{proof}
$\forall x\in\mathbb{N},\mu_i\in[0,1]:\sum\limits_{i=1}^{x}{\mu_i}=1:$
\begin{alignat*}{4}
	&f\Bigl(\frac{\lambda}{x}\Bigr)&&=f\Bigl(\sum\limits_{i=1}^x{\frac{\mu_i\lambda}{x}}\Bigr)&&\stackrel{\text{Jensen's inequality}}{\le}&&\sum\limits_{i=1}^x\frac{1}{x}f(\mu_i\lambda) \\
	&&&\Leftrightarrow xf\Bigl(\frac{\lambda}{x}\Bigr)&&\qquad\quad\le&&\sum\limits_{i=1}^xf(\mu_i\lambda)
\end{alignat*}
\end{proof}
Lemma~\ref{lem:share} tells us, that having $x_t$ active servers, it is always the best method to equally share $\lambda_t$ on all $x_t$ active servers. This allows us to uniquely identify an optimal schedule by the sequence of numbers of active servers $\mx$.\\ The costs of a schedule are then given by:
\begin{equation*}
	costs(\mx)\coloneqq\sum\limits_{t=0}^{T}{\underbrace{\beta\max\{0,x_{t}-x_{t-1}\}}_{\text{power up costs}}+x_tf(\lambda_t/t)}
\end{equation*}
We call a schedule $\mx$ \textbf{feasible} if $\forall t\in\{0,\ldots,T\}: x_t\ge\lambda_t$. In particular, every optimal schedule is feasible.

\section{Optimal scheduling for m homogeneous servers}\label{sec:opt}
TODO: introduction text

\subsection{Graph for an optimal schedule}\label{sec:optgraph}
We construct a directed acyclic graph as follows:\\
$\forall t\in[T-1]$ and $i,j\in\{0,\ldots,m\}$ we add vertices $(t,i)$ modelling the number of active servers at time t. Furthermore, we add vertices $(0,0)$ and $(T,0)$ for our initial and final state respectively.\\
In order to warrant that there are at least $\lceil\lambda_t\rceil$ active servers $\forall t\in[T-1]$, we define an auxiliary function which calculates the costs for handling an arrival rate $\lambda$ with $x$ active servers:
\begin{equation}
	c(x,\lambda)\coloneqq\begin{cases}
          0 & \text{if $x=0$}\\
	  xf(\lambda/x), & \text{if $x\ne 0\wedge\lambda\le x$}\\
	  \infty, & \text{otherwise}
	  \end{cases} \label{fct:c}
\end{equation}
Then, $\forall t\in[T-2]$ and $i,j\in\{0,\ldots,m\}$ we add edges from $(t,i)$ to $(t+1,j)$ with weight
\begin{equation}
	d(i,j,\lambda_{t+1})\coloneqq\beta\max\{0,j-i\}+c(j,\lambda_{t+1})
\end{equation}
Finally, for $0\le i\le m$ we add edges from $(0,0)$ to $(1,i)$ with weight $d(0,i,\lambda_1)$ and from $(T-1,i)$ to $(T,0)$ with weight $d(i,0,\lambda_T)=0$.
\begin{figure}[H]
\centering
\begin{tikzpicture}[->,>=stealth',auto,node distance=3cm,thick,node/.style={minimum size=1.2cm,circle,draw}]

  \node[node] (1) {0,0};
  \node[node] (4) [below right =of 1] {1,0};
  \node[node] (3) [above =0.5cm of 4] {1,1};
  \node[node] (2) [above right=of 1] {1,m};
  \node[node] (6) [right =of 3] {2,1};
  \node[node] (5) [right =of 2] {2,m};
  \node[node] (7) [right =of 4] {2,0};
  \node[node] (9) [right =of 6] {T-1,1};
  \node[node] (8) [right =of 5] {T-1,m};
  \node[node] (10) [right =of 7] {T-1,0};
  \node[node] (11) [above right =of 10] {T,0};

  \node at ($(5)!.4!(8)$) {\ldots};
  \node at ($(6)!.4!(9)$) {\ldots};
  \node at ($(7)!.4!(10)$) {\ldots};

  \node at ($(2)!.5!(3)$) {\vdots};
  \node at ($(2)!.5!(6)$) {\vdots};
  \node at ($(5)!.5!(6)$) {\vdots};
  \node at ($(8)!.5!(9)$) {\vdots};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node[left] {$d(0,m,\lambda_1)$} (2)
	edge node[above right=-0.1cm] {$d(0,1,\lambda_1)$} (3)
	edge node[left] {$d(0,0,\lambda_1)$} (4)
    (2) edge node[above] {$d(m,m,\lambda_2)$} (5)
    (3) edge (6)
	edge (7)
    (4) edge (6)
	edge node[below] {$d(0,0,\lambda_2)$} (7)
    (8) edge node[right] {$0$} (11)
    (9) edge node[above] {$0$} (11)
    (10) edge node[above] {$0$} (11);

   \path [->,draw,thick] (1) to ($(1)!.2!(8)$);
   \path [->,draw,thick] (2) to ($(2)!.4!(6)$);
   \path [->,draw,thick] (4) to ($(4)!.4!(5)$);
   \path [->,draw,thick] (3) to ($(3)!.4!(5)$);

   \path [->,draw,thick] ($(3)!.6!(5)$) to (5);
   \path [->,draw,thick] ($(2)!.6!(6)$) to (6);
   \path [->,draw,thick] ($(2)!.6!(7)$) to (7);

   \path [->,draw,thick] ($(6)!.6!(8)$) to (8);
   \path [->,draw,thick] ($(5)!.6!(8)$) to (8);

   \path [->,draw,thick] ($(5)!.6!(9)$) to (9);
   \path [->,draw,thick] ($(6)!.6!(9)$) to (9);
   \path [->,draw,thick] ($(7)!.6!(9)$) to (9);

   \path [->,draw,thick] ($(5)!.6!(10)$) to (10);
   \path [->,draw,thick] ($(6)!.6!(10)$) to (10);
   \path [->,draw,thick] ($(7)!.6!(10)$) to (10);

   \path[every node/.style={font=\sffamily\small}] [->,draw,thick] ($(2)!.8!(11)$) -- node[above] {0} ++ (11);

\end{tikzpicture}
\caption{Graph for optimal schedule algorithm.}
\end{figure}
\begin{remark} 
	All edges from $(t,i)$ to $(t+1,j)$ have weight $d(i,j,\lambda_{t+1})$
\end{remark}

\begin{prop}
	Any given optimal schedule $\mx$ corresponds to a shortest path $P$ from $(0,0)$ to $(T,0)$ with $costs(\mx)=costs(P)$ and vice versa.
\end{prop} 
\begin{proof}
$ $
\begin{itemize}
	\item[``$\Rightarrow$'':] We construct a feasible path in our graph from $\mx$ as follows:\\
$\forall t\in[T]$ set $e_t\coloneqq\Bigl(\bigl(t-1,\mx(t-1)\bigr),\bigl(t,\mx(t)\bigr)\Bigr)$. Then set $P\coloneqq(e_1,\ldots,e_{T})$.\\
	As each edge $e_t$ in our graph has weight $d\bigl(\mx(t-1),\mx(t),\lambda_{t}\bigr)$ and hence corresponds to the costs of switching from $\mx(t-1)$ to $\mx(t)$ servers and processing $\lambda_{t}$ with $\mx(t)$ active servers, it directly follows that $P$ is a shortest path of the graph with $costs(P)=costs(\mx)$.
	\item[``$\Leftarrow$'':] Let $P=\bigl((0,0)=v_0,\ldots,v_T=(T,0)\bigr)$ with $v_t\in\bigl\{(t,i)\mid 0\le i\le m\bigr\}$ be a shortest path of the graph.\\ 
	We can construct an optimal schedule from $P$ by setting $\mx\coloneqq\bigl(v_0(1),\ldots,v_T(1)\bigr)$\\
	By definition~(\ref{fct:c}) it is guaranteed that $P$ only traverses edges such that there are enough active servers $\forall t\in[T]$. Therefore, the created schedule is feasible. It's optimality directly follows from the definition of the edges' weights and so does the equality $costs(\mx)=costs(P)$.\\
\end{itemize}
\end{proof}

\subsection{A minimum cost algorithm}
\begin{algorithm}[H]
    \caption{Calculate costs for $m$ homogeneous servers}
    \begin{algorithmic}[1]
        \Require{Convex cost function $f$, $\lambda_0=\lambda_T=0$, $\forall t\in[T-1]:\lambda_t\in[0,m]$}
   \Function{schedule}{$m,T,\beta,\lambda_1,\ldots,\lambda_{T-1}$}
	\If{$T<2$} \Return
	\EndIf
	\Blet{$p[2\ldots T-1,m]$ and $M[1\ldots T-1,m]$}{new arrays}
	\For{$j \gets 0 \textrm{ to } m$}
		\Let{$M[1,j]$}{$d(0,j,\lambda_1)$}
	\EndFor
	\For{$t \gets 1 \textrm{ to } T-2$}
		\For{$j \gets 0 \textrm{ to } m$}
			\Let{$opt$}{$\infty$}
			\For{$i \gets 0 \textrm{ to } m$}
				\Let{$M[t+1,j]$}{$M[t,i]+d(i,j,\lambda_{t+1})$}
				\If{$M[t+1,j]<opt$}
					\Let{$opt$}{$M[t+1,j]$}
					\Let{$p[t+1,j]$}{$i$}
				\EndIf
			\EndFor
			\Let{$M[t+1,j]$}{$opt$}
		\EndFor
	\EndFor
	\State \Return{$p$ and $M$}
  \EndFunction
  \end{algorithmic}
\end{algorithm}
\begin{algorithm}[H]
    \caption{Extract schedule for n homogeneous servers}
    \begin{algorithmic}[1]
   \Function{Extract}{$m,p,M,T$}
	\Blet{$x[0\ldots T]$}{a new array}
	\Let{$x[0]$}{$x[T]\leftarrow 0$}
	\If{$T<2$} \Return $x$ \Comment{Trivial solution}
	\EndIf
	\Let{$x[T-1]$}{$\underset{0\le i\le m}{arg\ min}\{M[T-1,i]\}$}
	\For{$t \gets T-2 \textrm{ to } 1$}
		\Let{$x[t]$}{$p[t+1,x[t+1]]$}
	\EndFor
	\State \Return{$x$}
  \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsubsection{Runtime analysis}
Schedule: Loop 5,8 and 10 run $m+1$ times, loop 7 runs $T-2$ times\\
Extract: Loop 5 runs $T-2$ times, argmin 4 takes time $m+1$.\\
For $T,n\rightarrow\infty$ it holds:
\begin{equation}
	\mathcal{O}(m+1+(T-2)(m+1)^2+T-2+m+1)=\mathcal{O}(2m+T+(T-2)(m+1)^2)=\mathcal{O}(Tm^2) 
\end{equation}
As we need $\log_2(m)$ bits to encode m, the algorithm is exponential in the number of servers.

\subsubsection{A memory optimized algorithm}
TODO

\section{A $2$-approximation algorithm for monotonically increasing convex f}
We consider a modification of the problem discussed in chapter~\ref{sec:opt}. Assuming that f is convex and monotonically increasing, we can modify our algorithm to obtain a polynomial time $2$-approximation algorithm.

\subsection{Graph for a $2$-optimal schedule}
We modify our graph from chapter~\ref{sec:optgraph} to the reduce the number of vertices. For this, we stop adding m vertices for each timestep but using vertices that approximate the number of active servers. First, let $b\coloneqq\lceil\log_2(m)\rceil$. We add vertices $(t,0)$ and $(t,2^i),\forall t\in[T-1],0\le i\le b$. All edges and weights are added analogous to chapter~\ref{sec:optgraph}.
\begin{figure}[H]
\begin{tikzpicture}[->,>=stealth',auto,node distance=3cm,thick,node/.style={minimum size=1.2cm,circle,draw}]

  \node[node] (1) {0,0};
  \node[node] (4) [below right =of 1] {1,0};
  \node[node] (3) [above =0.5cm of 4] {1,$2^0$};
  \node[node] (2) [above right=of 1] {1,$2^b$};
  \node[node] (6) [right =of 3] {2,$2^0$};
  \node[node] (5) [right =of 2] {2,$2^b$};
  \node[node] (7) [right =of 4] {2,0};
  \node[node] (9) [right =of 6] {T-1,$2^0$};
  \node[node] (8) [right =of 5] {T-1,$2^b$};
  \node[node] (10) [right =of 7] {T-1,0};
  \node[node] (11) [above right =of 10] {T,0};

  \node at ($(5)!.4!(8)$) {\ldots};
  \node at ($(6)!.4!(9)$) {\ldots};
  \node at ($(7)!.4!(10)$) {\ldots};

  \node at ($(2)!.5!(3)$) {\vdots};
  \node at ($(2)!.5!(6)$) {\vdots};
  \node at ($(5)!.5!(6)$) {\vdots};
  \node at ($(8)!.5!(9)$) {\vdots};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node[left] {$d(0,2^b,\lambda_1)$} (2)
	edge node[above right=-0.1cm] {$d(0,2^0,\lambda_1)$} (3)
	edge node[left] {$d(0,0,\lambda_1)$} (4)
    (2) edge node[above] {$d(2^b,2^b,\lambda_2)$} (5)
    (3) edge (6)
	edge (7)
    (4) edge (6)
	edge node[below] {$d(0,0,\lambda_2)$} (7)
    (8) edge node[right] {$0$} (11)
    (9) edge node[above] {$0$} (11)
    (10) edge node[above] {$0$} (11);

   \path [->,draw,thick] (1) to ($(1)!.2!(8)$);
   \path [->,draw,thick] (2) to ($(2)!.4!(6)$);
   \path [->,draw,thick] (4) to ($(4)!.4!(5)$);
   \path [->,draw,thick] (3) to ($(3)!.4!(5)$);

   \path [->,draw,thick] ($(3)!.6!(5)$) to (5);
   \path [->,draw,thick] ($(2)!.6!(6)$) to (6);
   \path [->,draw,thick] ($(2)!.6!(7)$) to (7);

   \path [->,draw,thick] ($(6)!.6!(8)$) to (8);
   \path [->,draw,thick] ($(5)!.6!(8)$) to (8);

   \path [->,draw,thick] ($(5)!.6!(9)$) to (9);
   \path [->,draw,thick] ($(6)!.6!(9)$) to (9);
   \path [->,draw,thick] ($(7)!.6!(9)$) to (9);

   \path [->,draw,thick] ($(5)!.6!(10)$) to (10);
   \path [->,draw,thick] ($(6)!.6!(10)$) to (10);
   \path [->,draw,thick] ($(7)!.6!(10)$) to (10);

   \path[every node/.style={font=\sffamily\small}] [->,draw,thick] ($(2)!.8!(11)$) -- node[above] {0} ++ (11);

\end{tikzpicture}
\caption{Graph for $2$-approximation algorithm}
\end{figure}

\begin{prop}
$ $
\begin{enumerate}
	\item\label{prop:2opt} Any given optimal schedule $\mx$ can be transformed to a $2$-optimal schedule $\mx'$ which corresponds to a path $P$ from $(0,0)$ to $(T,0)$ with $costs(\mx')=costs(P)$.
	\item Any shortest path $P$ from $(0,0)$ to $(T,0)$ corresponds to a $2$-optimal schedule $\mx'$ with $costs(P)=costs(\mx')$.
\end{enumerate}
\end{prop}
\begin{proof}
$ $
\begin{enumerate}
	\item Assume we have an optimal schedule identified by $\mx=(x_0,\ldots,x_T)$. For $0\le t\le T$ we set:
	\begin{equation}
		x'_t\coloneqq 
		\begin{cases}
		  min\bigl\{2^{\lfloor \log_2(2x_t)\rfloor},2^b\bigr\}, & \text{if $x_t>0$}\\
		  0, & \text{otherwise}
		\end{cases} \label{def:xprime}
	\end{equation}
		Now let $\mx'\coloneqq(x'_0,\ldots,x'_T)$ be the modified sequence of active servers. Notice that \makebox{$x_t\le x'_t\le 2x_t$} holds as $x'_t$ is at most the smallest power of two larger than $x_t$ and therefore $\mx'$ is feasible. We can construct a feasible path in our graph from $\mathcal{X'}$ as follows:\\
	$\forall t\in[T]$ set $e_t\coloneqq\Bigl(\bigl(t-1,\mx'(t-1)\bigr),\bigl(t,\mx'(t)\bigr)\Bigr)$. Then set $P\coloneqq(e_1,\ldots,e_{T})$. By the definition of the edges' weights it follows $costs(\mx')=costs(P)$.\\
		Next, lets consider the difference of costs between $\mx'$ and $\mx$ at every time step $t$ to $t+1$ for $0\le t\le T-1$:
	The costs incurred by $\mx'$ are given by
	\begin{alignat}{2}
		&d\bigl(\mx'(t),\mx'(t+1),\lambda_{t+1}\bigr)&&=\beta\max\{0,x'_{t+1}-x'_t\}+c(x'_{t+1},\lambda_{t+1})\nonumber\\
		&\text{($\mx'$ is feasible)}	&&=\beta\max\{0,x'_{t+1}-x'_t\}+x'_{t+1}f(\lambda_{t+1}/x'_{t+1})\nonumber\\
		&\text(\ref{def:xprime}) &&\le\beta\max\{0,x'_{t+1}-x'_t\}+2x_{t+1}f(\lambda_{t+1}/x'_{t+1})\nonumber\\
		&\text{(f monotonically increasing)} &&\le\beta\max\{0,x'_{t+1}-x'_t\}+2x_{t+1}f(\lambda_{t+1}/x_{t+1})\label{eq:estxprime}
	\end{alignat}
	and the costs of $\mx$ by
	\begin{alignat}{2}
		&d\bigl(\mx(t),\mx(t+1),\lambda_{t+1}\bigr)&&=\beta\max\{0,x_{t+1}-x_t\}+c(x_{t+1},\lambda_{t+1})\nonumber\\
		&\text{($\mx$ is feasible)}&&=\beta\max\{0,x_{t+1}-x_t\}+x_{t+1}f(\lambda_{t+1}/x_{t+1})\label{eq:optcosts}
	\end{alignat}
	Therefore, we can estimate the difference:
	\begin{alignat}{3}
		&&&&&d(\mx'(t),\mx'(t+1),\lambda_{t+1})-d(\mx(t),\mx(t+1),\lambda_{t+1})\nonumber\\
		&\text{(\ref{eq:estxprime}),(\ref{eq:optcosts})}\quad&&\le\quad&&\beta\max\{0,x'_{t+1}-x'_t\}-\beta\max\{0,x_{t+1}-x_t\}+x_{t+1}f(\lambda_{t+1}/x_{t+1})\nonumber\\
		&&&=&&\beta\bigl(\max\{0,x'_{t+1}-x'_t\}-\max\{0,x_{t+1}-x_t\}\bigr)+x_{t+1}f(\lambda_{t+1}/x_{t+1})\label{eq:difxprime}
	\end{alignat}
	\begin{enumerate}[(i)]
		\item \underline{$x_{t+1}\le x_{t}$:}
			From (\ref{def:xprime}) it follows that $x'_{t+1}\le x'_{t}$. We continue to simplify~(\ref{eq:difxprime}):
		\begin{alignat*}{3}
			&&&&&\beta\bigl(\max\{0,x'_{t+1}-x'_t\}-\max\{0,x_{t+1}-x_t\}\bigr)+x_{t+1}f(\lambda_{t+1}/x_{t+1})\\
			&&&=\quad&&\beta(0-0)+x_{t+1}f(\lambda_{t+1}/x_{t+1})\\
			&&&=&&x_{t+1}f(\lambda_{t+1}/x_{t+1})\\
			&&&=&&d\bigl(\mx(t),\mx(t+1),\lambda_{t+1}\bigr)
		\end{alignat*}
		$\Rightarrow costs(\mx')=2costs(\mx)$
		\item \underline{$x_{t+1} > x_{t}$:}
		We simplify~(\ref{eq:difxprime}) and obtain
		\begin{alignat*}{3}
			&&&&&\beta\bigl(\max\{0,x'_{t+1}-x'_t\}-\max\{0,x_{t+1}-x_t\}\bigr)+x_{t+1}f(\lambda_{t+1}/x_{t+1})\\
			&&&=\quad&&\beta(x'_{t+1}-x'_t-x_{t+1}+x_t)+x_{t+1}f(\lambda_{t+1}/x_{t+1})\\
			&\text{(\ref{def:xprime})}\quad&&\le&&\beta(2x_{t+1}-x_t-x_{t+1}+x_t)+x_{t+1}f(\lambda_{t+1}/x_{t+1})\\
			&&&=&&\beta x_{t+1}+x_{t+1}f(\lambda_{t+1}/x_{t+1})\\
			&&&=&&d\bigl(0,\mx(t+1),\lambda_{t+1}\bigr)\\
			&&&\ne&&d\bigl(\mx(t),\mx(t+1),\lambda_{t+1}\bigr)
		\end{alignat*}
		Here we fail.
		%$\Rightarrow costs(\mx')=2costs(\mx)$
	\end{enumerate}
	%As the costs of $\mx'$ are at most twice the costs of $\mx$ at every time step, $\mx'$ corresponds to a $2$-optimal schedule.
	\item From (\ref{prop:2opt}) we obtain that we can construct a $2$-optimal path $P'$ from any optimal schedule. Now, let $P$ be a shortest path. We have $costs(P)\le costs(P')$ and as every feasible path in $P$ corresponds to an feasible schedule $\mx$ with $costs(P)=costs(\mx)$, $P$ must also be at least $2$-optimal.
\end{enumerate}
\end{proof}

\end{sloppypar}
\end{document}
